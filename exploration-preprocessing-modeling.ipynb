{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2479211cab97f1211d9050c19078b6435c3d0b22"
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d2c135c40bf5358517bbb500fdc644b499e3a60a"
      },
      "cell_type": "markdown",
      "source": "# Exploracion de datos"
    },
    {
      "metadata": {
        "_uuid": "bb66d62c75621f279a41e0eda6ec87b6f2bd3648"
      },
      "cell_type": "markdown",
      "source": "## Application train\n\nImportamos el dataset de entrenamiento, y revisamos sus estadisticas principales rapidamente."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "34ddc37af172b2a5a2bb30da5c7f8e9d748ce459"
      },
      "cell_type": "code",
      "source": "data_train = pd.read_csv('Data/application_train.csv')\nprint(data_train.shape)\ndata_train.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2d71123b6df6eaacab9fedfa444a122a96af1d2a"
      },
      "cell_type": "markdown",
      "source": "Al revisar las estadisticas que muestra la sentencia *data_train.describe()* observamos algo extraño en algunas columnas, como la columna *Days_Birth* que tiene valores negativos, y esto se debe a que las edades estan calculadas en dias y de manera relativa a la aplicación del prestamo."
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "8aff612717d3c1e0b17ef5fcf4fb6d6c45d67ff8"
      },
      "cell_type": "code",
      "source": "data_train.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "eba3c18f4e6484f46fa991ee91bbe357ed45fcfb"
      },
      "cell_type": "markdown",
      "source": "Para arreglar esta irregularidad en los datos, sacamos el valor absoluto de los dias que nos presenta el dataset, y para una vision mas comun de la edad, lo convertimos en años dividiendo por 365."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cd73abc599d06dc246e2b4af7fdb43663575ae70"
      },
      "cell_type": "code",
      "source": "data_train['DAYS_BIRTH'] = abs(data_train['DAYS_BIRTH'])/365",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "30c3094e76dee9d7df68960f906626ba80f9fa06"
      },
      "cell_type": "code",
      "source": "#revisamos con un boxplot que todo este mas o menos normal y no existan outliers exagerados\nplt.boxplot(data_train['DAYS_BIRTH'])\nplt.title('Boxplot de las edades')\nplt.ylabel('Edad en años');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9b40e61fbe269f82ec4e5236934d520370d9e3b8"
      },
      "cell_type": "markdown",
      "source": "Todo parece estar bien con las edades, ahora haremos lo mismo con la columna de *DAYS_EMPLOYED* que posee la misma irregularidad"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6f7983189c56c80415b548162318e9686474c90b"
      },
      "cell_type": "code",
      "source": "data_train['DAYS_EMPLOYED'] = abs(data_train['DAYS_EMPLOYED'])/365",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fd62faa840a4df64ada2c3b93d05ce77011fda63"
      },
      "cell_type": "code",
      "source": "plt.boxplot(data_train['DAYS_EMPLOYED'])\nplt.title('Boxplot de los años de trabajo')\nplt.ylabel('Años que lleva en el empleo actual.');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "334a458b6db389cb5571f03e443dfadbb3c9a757"
      },
      "cell_type": "markdown",
      "source": "Y se puede observar que existen outliers, y unos muy exagerados he ilogicos, tanto asi que hay algunos que han estado 1000 años en su ultimo empleo.\n- Estos Outliers se eliminaran inmediatamente, y quedaran como valores *NaN* porque es ilogico e imposible que una persona haya trabajado o vivido 1000 años.\n- Otra cosa importante, es que estos valores extraños, son todos iguales y equivalen a 1000.6657534246575 años de trabajo. **ENTONCES** cuando rellenemos estos valores *NaN* que crearemos, todos van a ser llenados con el mismo valor."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "659bfd3a70c0c13b038c8fdd0d07e216165bc214"
      },
      "cell_type": "code",
      "source": "weird_data = data_train[data_train['DAYS_EMPLOYED'] >= 1000]\n('Los datos raros corresponden a un %0.2f%% de todos los datos.' % (100*weird_data['DAYS_EMPLOYED'].shape[0]/data_train.shape[0]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f5ada5ea474b40e40b6aa0adf3614bb21f5a89fc"
      },
      "cell_type": "code",
      "source": "data_train['DAYS_EMPLOYED'].replace(1000.6657534246575, np.nan, inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1c2cd982c7a8639bf53a86dc112297201d4643fa"
      },
      "cell_type": "code",
      "source": "#Y graficamos de nuevo para ver el nuevo boxplot, llenando los Valores NaN con el promedio de la columna.\nDays_Job = data_train['DAYS_EMPLOYED'].copy()\nDays_Job.fillna(Days_Job.mean(), inplace=True)\nprint('Se siguen observando Outliers, pero mas logicos, ya que hay personas de mas de 60 años, es posible que lleven 40 años en el mismo trabajo')\nplt.boxplot(Days_Job)\nplt.ylabel('Años que lleva en el empleo actual');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bc7745f024cdf482afb6bd0040b426166665c0a5"
      },
      "cell_type": "markdown",
      "source": "- Revisamos las otras columnas que tienen el mismo formato de dias relativos a la aplicacion del credito, y las transformamos a valores positivos.\n- Los Outliers presentados en estas columnas se pueden pasar por alto, ya que son posibles."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4195130d7d9d801e8502d51b0b4c2bbbb1868717"
      },
      "cell_type": "code",
      "source": "data_train['DAYS_REGISTRATION'] = abs(data_train['DAYS_REGISTRATION'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9888dfa7f268fc5fe7d9a0d4c43998f0efa78c39"
      },
      "cell_type": "code",
      "source": "plt.boxplot(data_train['DAYS_REGISTRATION']);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "428ba4f5b169c660a155ae363e5a1d373d1a5186"
      },
      "cell_type": "code",
      "source": "data_train['DAYS_ID_PUBLISH'] = abs(data_train['DAYS_ID_PUBLISH'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a9a6143461c96c8bf87bf5327ae810b0a6e52efd"
      },
      "cell_type": "code",
      "source": "plt.boxplot(data_train['DAYS_ID_PUBLISH']);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "eb6cd0817f93ee8b41274f2af9a6740d26c829f8"
      },
      "cell_type": "markdown",
      "source": "Graficando se puede ver que nuestro dataset esta muy desbalanceado."
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "9a04be5f5a8fea72048e174d300b9e03347cef87"
      },
      "cell_type": "code",
      "source": "plt.figure(figsize=(5,3))\nplt.hist(data_train['TARGET'].astype(int))\nplt.xticks([0,1]);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c5e47d71e877314515ddf22842dcda91596e028f"
      },
      "cell_type": "markdown",
      "source": "Explicitamente se puede ver la proporcion de cada posible valor de nuestro TARGET"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "971c45113189915eeb5b26e5d23352847e7a995d"
      },
      "cell_type": "code",
      "source": "print('target 1 :', sum(data_train.TARGET==1), 'datos')\nprint('target 0 :', sum(data_train.TARGET==0), 'datos')\nprint('------------------')\nprint('%target 1 :', np.mean(data_train.TARGET==1))\nprint('%target 0 :', np.mean(data_train.TARGET==0))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3c1cace866bfb4a3e2759f7ca0eed9f849c6c0d7"
      },
      "cell_type": "markdown",
      "source": "Buscando valores NaN"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "133748ecaf58d9c5c57a30801daa12e5149f868e"
      },
      "cell_type": "code",
      "source": "print('valores NaN', data_train.isnull().sum().sum())\nprint('porcentaje de valores NaN en el DF:', 100*data_train.isnull().sum().sum()/(data_train.shape[0]*data_train.shape[1]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cd702d5f9715a7b4d973ea50aaccfa55a47b539b"
      },
      "cell_type": "markdown",
      "source": "Los valores NaN se trataran justo antes de empezar a realizar las predicciones, esto con el fin de probar varias maneras de llenar los valores NaN y escoger la que mejor rendimiento presente."
    },
    {
      "metadata": {
        "_uuid": "dc41a291228a04f3fe03f0093bef26dfd898a698"
      },
      "cell_type": "markdown",
      "source": "__________\n"
    },
    {
      "metadata": {
        "_uuid": "ba95491337bc5d126d5655d3268e2778f3c9d862"
      },
      "cell_type": "markdown",
      "source": "Buscando caracteristicas categoricas... obtenemos 16!"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4f3956e345226b826f0c14f831217716ffac4b59"
      },
      "cell_type": "code",
      "source": "data_train.dtypes.value_counts()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3e7b0e05f996fa0e3d62df120fd897c671031813"
      },
      "cell_type": "markdown",
      "source": "revisando cuantos valores unicos poseen las caracteristicas categoricas"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "656bdbf9f1708ddbb6d987ab83b4e51d9655525f"
      },
      "cell_type": "code",
      "source": "obj_columns = data_train.dtypes[data_train.dtypes.values == 'object'].index.tolist()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "1ab6d33bfff6d7b974f14467dbc74c3cd3c4d13f"
      },
      "cell_type": "code",
      "source": "print(data_train[obj_columns].apply(pd.Series.nunique, axis = 0))\nprint('cantidad de elementos unicos en las variables categoricas', data_train[obj_columns].apply(pd.Series.nunique, axis = 0).values.sum())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "489a713b7ed3003694ef93ac59fc64925aa668e1"
      },
      "cell_type": "markdown",
      "source": "Tienen muy pocos valores unicos"
    },
    {
      "metadata": {
        "_uuid": "cf93b732f8ee6207a6dda37a23fe23b1ad4fba85"
      },
      "cell_type": "markdown",
      "source": "## Application Test\n\nDataset de testeo. Se le realiza el mismo analisis que al anterior.\n\nA primera vista se ve que el conjunto de testeo es significativamente mas pequeño que el conjunto de entrenamiento."
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "0d2abb5b16de2292e0e5816a42db53f050b2f5a5"
      },
      "cell_type": "code",
      "source": "data_test = pd.read_csv('Data/application_test.csv')\nprint(data_test.shape)\ndata_test.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "7f7039a64e7eaa492bba475150081b54caca6b9f"
      },
      "cell_type": "code",
      "source": "data_test.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a2cd0784db432e7600df616f5a6f470b581721e9"
      },
      "cell_type": "markdown",
      "source": "**Checkeo y Correccion de irregularidades en las columnas del dataset**  \nSe realiza el mismo proceso que se uso en el dataset de entrenamiento para corregir las irregularidades encontradas."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "76a8280a8536276ddc17fb99d5f1b3195c208d26"
      },
      "cell_type": "code",
      "source": "data_test['DAYS_BIRTH'] = abs(data_test['DAYS_BIRTH'])/365",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "ad74735d1ae17917cdafa90cc0529e43bfb0b2a0"
      },
      "cell_type": "code",
      "source": "#Todo parece estar en orden con las edades\nplt.boxplot(data_test['DAYS_BIRTH'])\nplt.title('Boxplot de las edades.')\nplt.ylabel('Edad.');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ba28669241986fefab52a928d59cab492193a023"
      },
      "cell_type": "markdown",
      "source": "Para los dias de empleo que tiene en el trabajo actual"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "86c488b88280d375a609535ea0a6673c923d3a2d"
      },
      "cell_type": "code",
      "source": "data_test['DAYS_EMPLOYED'] = abs(data_test['DAYS_EMPLOYED'])/365",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "811831e0f274cd2651312a34c1303629c125d943"
      },
      "cell_type": "code",
      "source": "#Todo parece estar en orden con las edades\nplt.boxplot(data_test['DAYS_EMPLOYED'])\nplt.title('Boxplot de los años de trabajo')\nplt.ylabel('Años que lleva en el empleo actual.');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b69b645b53f5d9cd97e23ba7037d73132b9005d2"
      },
      "cell_type": "code",
      "source": "data_test['DAYS_EMPLOYED'].replace(1000.6657534246575, np.nan, inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "55d426a93405fb87b055096da53c562b2f9243c8"
      },
      "cell_type": "code",
      "source": "print('Maximo valor: ', data_test['DAYS_EMPLOYED'].max())\nprint('Minimo valor', data_test['DAYS_EMPLOYED'].min())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bc67702dd4fd152ff7abff2f558f043420a6a8a6"
      },
      "cell_type": "markdown",
      "source": "Para las otras dos variables del mismo formato."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "79a0cbfe1be065709f8690a6d19e5c6db134e247"
      },
      "cell_type": "code",
      "source": "data_test['DAYS_REGISTRATION'] = abs(data_test['DAYS_REGISTRATION'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b7710bcd418f37cfd12a091ddcef402c0425fc04"
      },
      "cell_type": "code",
      "source": "print('Maximo valor: ', data_test['DAYS_REGISTRATION'].max())\nprint('Minimo valor', data_test['DAYS_REGISTRATION'].min())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "98a5f13a098829f396d34c4983b02eaf179bce85"
      },
      "cell_type": "code",
      "source": "data_test['DAYS_ID_PUBLISH'] = abs(data_test['DAYS_ID_PUBLISH'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "1d7d83b3873db6669cd152f594a063cf0f3c3b63"
      },
      "cell_type": "code",
      "source": "print('Maximo valor: ', data_test['DAYS_ID_PUBLISH'].max())\nprint('Minimo valor', data_test['DAYS_ID_PUBLISH'].min())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3b5bf4c20a808e4c49f265ff51df3d64e87c6bb0"
      },
      "cell_type": "markdown",
      "source": "**Reviso los valores NaN**\n\nSe puede notar que la proporcion de valores NaN no varia mucho en comparación al dataset de entrenamiento."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4a3c896f3e39b21ae23189bdd7d6814ab822bc43"
      },
      "cell_type": "code",
      "source": "print('valores NaN', data_test.isnull().sum().sum())\nprint('porcentaje de valores NaN en el DF es de %0.2f%%' %(100*data_test.isnull().sum().sum()/(data_test.shape[0]*data_test.shape[1])))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7097164b0e21c5007d143d18ffa18d526b93105a"
      },
      "cell_type": "markdown",
      "source": "**Buscando las columnas categoricas**  \nAl tratarse de la parte de un mismo archivo, se puede ver que el dataset de testeo posee las mismas columnas categoricas que el dataset de entrenamiento"
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "b2d047d41f7ba303bce5a3a130b873c7f4d44715"
      },
      "cell_type": "code",
      "source": "data_test.dtypes.value_counts()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "72f48f4e28ece43487de8400ce354ef80f554261"
      },
      "cell_type": "code",
      "source": "obj_columns = data_test.dtypes[data_test.dtypes.values == 'object'].index.tolist()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0e3893b71a731e1cf20c745b52b09373def16f8e"
      },
      "cell_type": "code",
      "source": "print(data_test[obj_columns].apply(pd.Series.nunique, axis = 0))\nprint('cantidad de elementos unicos en las variables categoricas', data_test[obj_columns].apply(pd.Series.nunique, axis = 0).values.sum())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a1f5d362654504eb2d3702783a6df44536a79e12"
      },
      "cell_type": "markdown",
      "source": "***Aunque si se nota un leve cambio en la cantidad de valores unicos que poseen las columnas categoricas.***"
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "473778c82d61271000f9ed2495efea4b472db246"
      },
      "cell_type": "markdown",
      "source": "# Pre-Procesado de datos\n\n### Codificación de las caracteristicas categoricas\n\n- Usando LabelEncoder para las caracteristicas con 2 categorias\n- Usando OneHotEncoder (para crear variables Dummy) para las caracteristicas que tengan mas de 2 categorias"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "07452e5f835143ce24c78a5a47b6b3203e08211d"
      },
      "cell_type": "code",
      "source": "from sklearn.preprocessing import LabelEncoder",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f9f818c88e7f7e922742db2f9ceadb058101b086"
      },
      "cell_type": "code",
      "source": "label = LabelEncoder()\n\nfor i in obj_columns:\n    if len(data_train[i].unique()) <= 2:\n        #entreo el objeto encoder\n        label.fit(data_train[i])\n        #aplico la transformacion en los dos DF principales.\n        data_train[i] = label.transform(data_train[i])\n        data_test[i] = label.transform(data_test[i])\n\n#Ahora codificar las que tienen mas de 2 categorias.\ndata_train = pd.get_dummies(data_train)\ndata_test = pd.get_dummies(data_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e65aaeb169dc68b993243114419c858487366649"
      },
      "cell_type": "code",
      "source": "print('Nuevas dimensiones del DF:', data_train.shape)\nprint('Nuevas dimensiones del DF:', data_test.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ac2759d72ecb9b6794ca4be1d197efffcac84ee3"
      },
      "cell_type": "markdown",
      "source": "Por esta razon tenemos que modificar los dataset de entrenamiento y prueba, ya que deben tener la misma cantidad de columnas para que el modelo predictivo que se cree nos sirva.  \n\n- Se penso en usar el metodo Join, pero el metodo JOIN nos retornaria un solo dataset, y nosotros necesitamos tener los dos, entonces...\n- Se usara el metodo Align para \"alinear\" los dos archivos y que queden con un mismo numero de columnas, sin tener que necesariamente unirlos."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c7c9fbb8b22b956a3cd53cdff48d00528d7d6192"
      },
      "cell_type": "code",
      "source": "#Lo primero es salvar nuestra columna de TARGET, porque esta columna no esta en el dataset de pruebas\nTargets = data_train['TARGET']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2feb613cf2d155e98cd9cf267735a52a5934227c"
      },
      "cell_type": "code",
      "source": "#hacemos uso del metodo align, que nos permite \"recortar\" los dataframes para que queden con la misma\n#cantidad de columnas. (Usamos las columnas que tienen en comun los dos dataframes)\n#Usamos axis = 1 para que nos realice el proceso por columnas y no por filas.\ndata_train, data_test = data_train.align(data_test, join='inner', axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "818ab25b9ab80e4ac7a2b8da6e14b60614c4b5a5"
      },
      "cell_type": "code",
      "source": "#Ahora solo hay que agregar de nuevo la columna de los TARGETS a nuestro nuevo dataset de entrenamiento\ndata_train['TARGET'] = Targets",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b8dc31bf47d5c3f2debc917f7c31c9274d89d7f6"
      },
      "cell_type": "code",
      "source": "print('Nuevas dimensiones del DF:', data_train.shape)\nprint('Nuevas dimensiones del DF:', data_test.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ed2e9e854ac8a79de02084bc5d5c58dedc0d0176"
      },
      "cell_type": "markdown",
      "source": "## Feature Engineering\n\n### Buscando Correlaciones\nEste paso es muy importante ya que podemos encontrar que caracteristicas afectan mas a nuestro *TARGET*"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bd90e3359c1b7d1f16d6e84a71900175d8243d58"
      },
      "cell_type": "code",
      "source": "corrs = data_train.corr()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3bf4ecc2693276634f865ff267b305991615721e"
      },
      "cell_type": "markdown",
      "source": "Nos interesa ver las correlaciones de las variables contra nuestra variable *TARGET*"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7812b6a5b6a59456c4f782d7bc215ad9335f7e8b"
      },
      "cell_type": "code",
      "source": "corrs.sort_values('TARGET', inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a5e6f606b6ebb0cb9fddbe5592bc322af96aac40"
      },
      "cell_type": "code",
      "source": "corrs = corrs['TARGET']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3f3cf7b8534826d9d15ee873f13e9a8edc104a09"
      },
      "cell_type": "code",
      "source": "corrs.head(10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ca3a9cf7dd543803fff9dcca083aedf5786e1f63"
      },
      "cell_type": "code",
      "source": "corrs.tail(10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "19ccb9d1aa6be2868c6c81ea16819ecfcab5eb74"
      },
      "cell_type": "markdown",
      "source": "Se puede observar que las columnas que afectan mas de manera positiva son:\n- CODE_GENDER_M                                      \n- DAYS_LAST_PHONE_CHANGE                            \n- NAME_INCOME_TYPE_Working                            \n- REGION_RATING_CLIENT                                \n- REGION_RATING_CLIENT_W_CITY \n\nY las que mas afectan de manera negativa son:\n- EXT_SOURCE_3                        \n- EXT_SOURCE_2                         \n- EXT_SOURCE_1                        \n- DAYS_BIRTH                            \n- DAYS_EMPLOYED                          "
    },
    {
      "metadata": {
        "_uuid": "1790eabd4672ee59a27a5a12fdcb1cf64816755c"
      },
      "cell_type": "markdown",
      "source": "Obteniendo las caracteristicas mas importantes con otro metodo... Entrenando un RandomForestClassifier.\n\nPero primero debemos rellenar los NaN  \n\n**Tratamiento de los valores NaN**\n\n- Lo primero es obtener las columnas que poseen valores NaN.\n- Y luego rellenar los valores NaN con alguna estrategia."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f82f140b1f5114776c945433f2a3922bbf226da2"
      },
      "cell_type": "code",
      "source": "columns_NaN = data_train.isnull().sum()[data_train.isnull().sum().values > 0].index.tolist()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "95e13ff20d0df7d896d0b2c9ea02d092c3c6a832"
      },
      "cell_type": "code",
      "source": "data_train['OWN_CAR_AGE'].fillna(0, inplace=True)\ndata_train.fillna(np.mean(data_train), inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "54a92050a9354e744f0f86fbfbd91c28d6c60b83"
      },
      "cell_type": "markdown",
      "source": "Ahora el mismo procedimiento para el dataset de test"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eaa104e74b3378bb6a24bedd95d8efd42040ab13"
      },
      "cell_type": "code",
      "source": "columns_NaN = data_test.isnull().sum()[data_test.isnull().sum().values > 0].index.tolist()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a2758ed9a949a2211eb92094178da8259d2a7272"
      },
      "cell_type": "code",
      "source": "data_test['OWN_CAR_AGE'].fillna(0, inplace=True)\ndata_test.fillna(np.mean(data_test), inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "75fad747a2bf928f2f2df8ebb4a1d0cf86a4f312"
      },
      "cell_type": "markdown",
      "source": "### Creando un bosque aleatorio clasificador para obtener la importancia de las caracteristicas"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5050a9bd9bedfd88ee68749b61932cfe65cb1879"
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3ee4b68b1dd78ff238ee0f7498608eaaa103c565"
      },
      "cell_type": "code",
      "source": "RFC = RandomForestClassifier()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2914deaff86c9ec8eda431655342e2f4eeee0ba3"
      },
      "cell_type": "code",
      "source": "cl = data_train.columns.values.tolist()\ncl.remove('TARGET')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "69e2092dee7423623f6aae94bf1238a6e5bf5054"
      },
      "cell_type": "code",
      "source": "cl = data_train.columns.values.tolist()\ncl.remove('TARGET')\nX = data_train.filter(cl)\ny = data_train['TARGET']\nRFC.fit(X, y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "72f3cf1eb546194462d805d8d57eec32b1cffa56"
      },
      "cell_type": "code",
      "source": "plt.figure(figsize=(15,5))\nplt.bar(X.columns.values.tolist()[:35], RFC.feature_importances_[:35])\nplt.xticks(rotation=90);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e94ec52368009a559ed793932266e2cdbd59b2c3"
      },
      "cell_type": "markdown",
      "source": "Como se observo anteriormente con el coeficiente de pearson (con la funcion de pandas .corr()) los campos que mas afectan a nuestro *TARGET* son los de EXT_SORCE_#, y otros como el *INCOME_TOTAL*, *AMT_ANNUITY*, *GOODS_PRICE*, *DAYS_EMPLOYED*, entre otros como se ve en la anterior grafica.  \nY algo curioso es que la edad *DAYS_BIRTH* afecta.  "
    },
    {
      "metadata": {
        "_uuid": "e963783d00f0511c1cf04904ffb8a7dfe613431f"
      },
      "cell_type": "markdown",
      "source": "### Re-Escalado de los datos\nEs necesario hacerlo para que una columna no influya mucho mas que otra por la escala en la que estan los datos."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9041d77cb54e782b24abfea25bbc2f5124373e7d"
      },
      "cell_type": "code",
      "source": "from sklearn.preprocessing import MinMaxScaler",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e8bbe0d9b7865d6c619db95c2d4cacd494f0c818"
      },
      "cell_type": "code",
      "source": "scaler = MinMaxScaler(feature_range=(0,1))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1ca4e84e28b29ea75cce7d0fe6e171278a6a6ee4"
      },
      "cell_type": "code",
      "source": "scaler.fit(X)\nX_train = scaler.transform(X)\nX_test = scaler.transform(data_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "084c80a2f24e0786c1af99cc3011175cb5dd9dc9"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d60addeb0c2afaf4e49728e70d7a8721885c5e56"
      },
      "cell_type": "markdown",
      "source": "## Hago una predicción"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9034dd20bd3384e89f7a0af7dbeaa5ae03ea0185"
      },
      "cell_type": "code",
      "source": "from sklearn.linear_model import LogisticRegression",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "aa9887ca3925d472ab262e2a607e7d1bb683690a"
      },
      "cell_type": "code",
      "source": "LR = LogisticRegression()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "de8884cd1a5ca8b73b68bbbea4c525795369ee61"
      },
      "cell_type": "code",
      "source": "LR.fit(X_train, y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eb24bfa386504b764c9f9c67ff214acbc66e457a"
      },
      "cell_type": "code",
      "source": "#Usamos el metodo predict_proba ya que este nos devuelve un array de n x 2, donde n son\n#las observaciones, y 2 son las columnas, la primera columna para las probabilidades de \n#que salga 0 y la segunda para las probabilidades de 1. Para nuestro reto necesitamos \n#la segunda columna.\nresult = LR.predict_proba(X_test)[:,1]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1978bf91bdafd1670136689c91a356370de8c56d"
      },
      "cell_type": "markdown",
      "source": "Ahora que tenemos las probabilidades, tenemos que crear el archivo con el formato que exige la competencia de kaggle para obtener nuestro score."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "552af6961254677ed437c666c71f7debb71f7988"
      },
      "cell_type": "code",
      "source": "submission = data_test[['SK_ID_CURR']]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "de0c3b3605481ac7517b304dd9b2aecbe3f0808f"
      },
      "cell_type": "code",
      "source": "submission['TARGET'] = result",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eb288488e9f53dd200426a7ec96c40ca64783046"
      },
      "cell_type": "code",
      "source": "submission.head(10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d67a36d3412e45dbf75c66d2a23e65aeebe6ecdb"
      },
      "cell_type": "code",
      "source": "submission.to_csv('submission.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7f4b5543e661186ccd94d75e533dc90235225803"
      },
      "cell_type": "markdown",
      "source": "### Reduccion de dimensionalidad con PCA"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d217e8fdf82f56be578e1614fceb7429ff70121a"
      },
      "cell_type": "code",
      "source": "from sklearn.decomposition import PCA",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "91f1c4c2e4629c66cf3c9ccddb70ab09fe533b93"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
